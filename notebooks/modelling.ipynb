{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risco de Crédito\n",
    "\n",
    "Faça um modelo para prever o risco de inadimplência de um cliente utilizando apenas dados de acquisição, ou seja, apenas dados que são conhecidos na fase de aplicação deste. Lembre-se que o limite inicial é definido após o cliente ser aceito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  acq_train\n",
    "Y = acq_y.target_fraud\n",
    "SEED = 10\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,Y,\n",
    "                                                   test_size=0.25,\n",
    "                                                   random_state=0,\n",
    "                                                   stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_selection():\n",
    "    models = [\n",
    "        ('XGB'   , XGBClassifier()),\n",
    "        ('LGBM'   , LGBMClassifier()),\n",
    "        ('DT'   , DecisionTreeClassifier()),\n",
    "        ('KN'   , KNeighborsClassifier()),\n",
    "        ('LDA'   , LinearDiscriminantAnalysis()),\n",
    "        ('GNB'   , GaussianNB()),\n",
    "        ('RF'   , RandomForestClassifier()),\n",
    "    ]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasedLine(X_train, y_train,models):\n",
    "    # Test options and evaluation metric\n",
    "    num_folds = 5\n",
    "    scoring = 'roc_auc'\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=num_folds, random_state=SEED)\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        \n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw/'\n",
    "\n",
    "# acquisition_test = pd.read_csv('../data/raw/acquisition_test.csv')\n",
    "# spend_train = pd.read_csv('../data/raw/spend_train.csv')\n",
    "\n",
    "\n",
    "def make_base_default():\n",
    "    \"\"\"\n",
    "    Make an base-line dataset ready for the default model.\n",
    "    \"\"\"\n",
    "    acquisition_train = pd.read_csv(data_dir + 'acquisition_train.csv')\n",
    "    acquisition_test = pd.read_csv(data_dir + 'acquisition_test.csv')\n",
    "\n",
    "    datasets = [acquisition_train, acquisition_test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model default_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "data_dir = '../data/'\n",
    "\n",
    "# acquisition_test = pd.read_csv('../data/raw/acquisition_test.csv')\n",
    "# spend_train = pd.read_csv('../data/raw/spend_train.csv')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make an base-line dataset ready for the default model.\n",
    "\"\"\"\n",
    "acquisition_train = pd.read_csv(data_dir + 'raw/acquisition_train.csv')\n",
    "acquisition_test = pd.read_csv(data_dir + 'raw/acquisition_test.csv')\n",
    "dataframes = [acquisition_train, acquisition_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop target_fraud column\n",
    "acquisition_train.drop('target_fraud', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing target_default values of train\n",
    "acquisition_train.target_default.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set target_default dtype to numeric\n",
    "acquisition_train.target_default = acquisition_train.target_default.astype(np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the obj (non-numeric) columns names\n",
    "obj_cols = df.select_dtypes(exclude=pd.np.number).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    # fill missing values with unique value\n",
    "    df.fillna(-9999, inplace=True)\n",
    "    # change obj columns dtypes to str for encoding\n",
    "    df[obj_cols] = df[obj_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables\n",
    "for col in obj_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([acquisition_train[col], acquisition_test[col]]))\n",
    "    for df in dataframes:\n",
    "        df[col] = le.transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the ptdraft folder path to the sys.path list\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-05 11:54:08,792 INFO     Reading datasets.\n",
      "2018-10-05 11:54:09,548 INFO     Train shape (45000, 43), Test shape (19592, 41)\n",
      "2018-10-05 11:54:09,549 INFO     Preprocessing columns.\n",
      "2018-10-05 11:54:09,846 INFO     Encoding categorical columns.\n",
      "2018-10-05 11:54:10,585 INFO     Saving datasets in /home/andre/Study/DataChallenge/Nubank/nubank_data_challenge/data/processed.\n"
     ]
    }
   ],
   "source": [
    "make_dataset.default_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<module 'data.make_dataset' from '../src/data/make_dataset.py'>\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dataset.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aa15c7d69d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<module 'data' from '../src/data/__init__.py'>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-challenge",
   "language": "python",
   "name": "data-challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
